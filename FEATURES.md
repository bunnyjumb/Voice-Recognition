# Meeting Summary Assistant - TÃ i liá»‡u Ä‘áº§y Ä‘á»§

## Tá»•ng quan

Meeting Summary Assistant lÃ  má»™t á»©ng dá»¥ng web Flask cho phÃ©p ngÆ°á»i dÃ¹ng upload hoáº·c ghi Ã¢m audio, tá»± Ä‘á»™ng chuyá»ƒn Ä‘á»•i thÃ nh vÄƒn báº£n (transcription) vÃ  táº¡o tÃ³m táº¯t cuá»™c há»p báº±ng AI.

## Kiáº¿n trÃºc á»©ng dá»¥ng

### Cáº¥u trÃºc thÆ° má»¥c

```
Python/
â”œâ”€â”€ app.py                          # Flask application chÃ­nh
â”œâ”€â”€ config.py                       # Cáº¥u hÃ¬nh vÃ  constants
â”œâ”€â”€ requirements.txt                # Dependencies
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html                 # Frontend UI
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ audio_service.py           # Xá»­ lÃ½ file audio
â”‚   â”œâ”€â”€ audio_compressor.py        # NÃ©n audio files
â”‚   â”œâ”€â”€ audio_splitter.py          # Chia nhá» audio files
â”‚   â”œâ”€â”€ ai_service.py              # AI transcription & summarization
â”‚   â””â”€â”€ whisper_model_cache.py     # Cache Whisper models Ä‘á»ƒ tá»‘i Æ°u performance
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ prompt_builder.py          # Táº¡o prompts cho AI
â”‚   â”œâ”€â”€ text_chunker.py            # Chia nhá» text dÃ i
â”‚   â”œâ”€â”€ vietnamese_postprocessor.py # Post-processing cho tiáº¿ng Viá»‡t
â”‚   â”œâ”€â”€ message_manager.py         # Quáº£n lÃ½ conversation history
â”‚   â”œâ”€â”€ function_calling.py        # Function calling cho OpenAI
â”‚   â””â”€â”€ batch_processor.py         # Batch processing
â””â”€â”€ uploads/                       # ThÆ° má»¥c lÆ°u files
```

## Luá»“ng xá»­ lÃ½ tá»« Ä‘áº§u Ä‘áº¿n cuá»‘i

### 1. Frontend (index.html)

**Chá»©c nÄƒng:**
- Form nháº­p liá»‡u: Meeting Topic, Language
- Upload file audio hoáº·c ghi Ã¢m trá»±c tiáº¿p
- Hiá»ƒn thá»‹ progress bar vÃ  káº¿t quáº£
- Validation phÃ­a client

**Workflow:**
1. User nháº­p topic vÃ  chá»n language
2. User upload file hoáº·c ghi Ã¢m
3. JavaScript validate form
4. Gá»­i POST request Ä‘áº¿n `/process-audio` vá»›i FormData
5. Hiá»ƒn thá»‹ progress bar (simulated)
6. Nháº­n káº¿t quáº£ vÃ  hiá»ƒn thá»‹ summary

### 2. Backend API Routes

#### Route: `/` (GET)
- Render trang chá»§ (index.html)
- KhÃ´ng xá»­ lÃ½ logic

#### Route: `/process-audio` (POST)
**Input:**
- `audio_data`: File audio (multipart/form-data)
- `topic`: Meeting topic (required)
- `language`: Language code (required)
- `custom_language`: Custom language náº¿u chá»n "other"

**Workflow:**
1. **Validation**: Kiá»ƒm tra AI service available, file tá»“n táº¡i, form data há»£p lá»‡
2. **Save File**: LÆ°u file audio vÃ o thÆ° má»¥c uploads
3. **Transcription**: Chuyá»ƒn audio thÃ nh text
4. **Summarization**: Táº¡o summary tá»« transcript
5. **Response**: Tráº£ vá» JSON vá»›i summary vÃ  download URL

**Output:**
```json
{
  "summary": "Meeting summary text...",
  "download_url": "/uploads/recording_xxx.mp3"
}
```

#### Route: `/check-ffmpeg` (GET)
- Kiá»ƒm tra FFmpeg cÃ³ sáºµn khÃ´ng
- Tráº£ vá» JSON vá»›i status

#### Route: `/uploads/<filename>` (GET)
- Serve static files tá»« thÆ° má»¥c uploads

### 3. Audio Service (audio_service.py)

**Class: AudioService**

**Chá»©c nÄƒng:**
- LÆ°u file audio vá»›i tÃªn unique (timestamp-based)
- Quáº£n lÃ½ thÆ° má»¥c uploads
- Validate file existence

**Methods:**
- `save_audio_file(file)`: LÆ°u file vÃ  tráº£ vá» (filepath, filename)
- `get_file_path(filename)`: Láº¥y full path cá»§a file
- `file_exists(filename)`: Kiá»ƒm tra file cÃ³ tá»“n táº¡i khÃ´ng

### 4. AI Service (ai_service.py)

**Class: AIService**

**Chá»©c nÄƒng chÃ­nh:**
- Transcription: Chuyá»ƒn audio thÃ nh text
- Summarization: Táº¡o summary tá»« text

#### 4.1 Transcription Workflow

**Method: `transcribe_audio(audio_file_path, language)`**

**Quy trÃ¬nh xá»­ lÃ½:**

1. **Kiá»ƒm tra file size**
   - Náº¿u â‰¤ 25MB: Transcribe trá»±c tiáº¿p
   - Náº¿u > 25MB: Cáº§n compression/splitting

2. **Compression (náº¿u file lá»›n)**
   - Sá»­ dá»¥ng AudioCompressor
   - Cáº§n FFmpeg
   - NÃ©n xuá»‘ng < 25MB náº¿u cÃ³ thá»ƒ

3. **Splitting (náº¿u váº«n lá»›n)**
   - Sá»­ dá»¥ng AudioSplitter
   - Chia thÃ nh nhiá»u chunks â‰¤ 25MB
   - Má»—i chunk Ä‘Æ°á»£c transcribe riÃªng
   - Káº¿t há»£p cÃ¡c transcripts láº¡i

4. **Transcription Method Selection**
   - **API First**: Thá»­ OpenAI Whisper API trÆ°á»›c
   - **Fallback**: Náº¿u API fail (404), dÃ¹ng local Whisper

5. **Local Whisper Transcription**
   - Load Whisper model tá»« cache (WhisperModelCache)
   - Models Ä‘Æ°á»£c preload khi server start (background thread)
   - Model selection:
     - Vietnamese: "medium" (better accuracy)
     - Other languages: "base" (balance speed/accuracy)
   - Models chá»‰ load 1 láº§n, reuse cho cÃ¡c requests sau
   - Transcribe vá»›i language hint
   - Post-processing cho tiáº¿ng Viá»‡t (náº¿u cáº§n)

6. **Post-processing (Vietnamese only)**
   - Sá»­a lá»—i chÃ­nh táº£ phá»• biáº¿n
   - Chuáº©n hÃ³a Ä‘á»‹nh dáº¡ng
   - Cáº£i thiá»‡n cháº¥t lÆ°á»£ng text

**Method: `_transcribe_single_file(audio_file_path, language)`**

- Transcribe má»™t file Ä‘Æ¡n láº» (â‰¤ 25MB)
- Thá»­ API trÆ°á»›c, fallback local Whisper
- Return transcript text

**Method: `_transcribe_with_local_whisper(audio_file_path, language)`**

- Kiá»ƒm tra FFmpeg available
- Load Whisper model tá»« cache (náº¿u chÆ°a cÃ³ thÃ¬ load vÃ  cache)
- Transcribe audio (CPU-intensive, cÃ³ thá»ƒ máº¥t vÃ i phÃºt)
- Log estimated vÃ  actual processing time
- Post-process náº¿u lÃ  tiáº¿ng Viá»‡t
- Return transcript

#### 4.2 Summarization Workflow

**Method: `summarize_transcript(transcript, topic, language, custom_language)`**

**Quy trÃ¬nh:**

1. **Kiá»ƒm tra Ä‘á»™ dÃ i transcript**
   - Náº¿u â‰¤ 2000 chars: Summarize trá»±c tiáº¿p
   - Náº¿u > 2000 chars: Chunked summarization

2. **Single Chunk Summarization**
   - Táº¡o prompt tá»« PromptBuilder
   - Gá»i OpenAI API vá»›i GPT model
   - Return summary

3. **Chunked Summarization**
   - Chia transcript thÃ nh chunks (2000 chars/chunk, overlap 200)
   - Summarize tá»«ng chunk
   - Combine chunk summaries
   - Táº¡o final summary tá»« combined summaries

**Method: `_summarize_single_chunk(...)`**
- Summarize má»™t chunk text
- Sá»­ dá»¥ng PromptBuilder Ä‘á»ƒ táº¡o prompts
- Gá»i OpenAI API

**Method: `_summarize_chunked(...)`**
- Chia text thÃ nh chunks
- Summarize tá»«ng chunk
- Combine vÃ  táº¡o final summary

### 5. Audio Processing Services

#### AudioCompressor (audio_compressor.py)
- NÃ©n audio files Ä‘á»ƒ giáº£m kÃ­ch thÆ°á»›c
- Sá»­ dá»¥ng FFmpeg
- Presets: high/medium/low compression

#### AudioSplitter (audio_splitter.py)
- Chia audio files thÃ nh chunks
- Sá»­ dá»¥ng FFmpeg
- Má»—i chunk â‰¤ 25MB
- Preserve audio quality

### 6. Utility Modules

#### PromptBuilder (prompt_builder.py)
- Táº¡o prompts cho AI summarization
- Support multiple languages
- Structured vÃ  standard prompts
- Preserve technical terms

#### TextChunker (text_chunker.py)
- Chia text dÃ i thÃ nh chunks
- Intelligent splitting (sentence boundaries)
- Overlap Ä‘á»ƒ preserve context

#### VietnamesePostProcessor (vietnamese_postprocessor.py)
- Sá»­a lá»—i chÃ­nh táº£ tiáº¿ng Viá»‡t
- Chuáº©n hÃ³a Ä‘á»‹nh dáº¡ng
- Cáº£i thiá»‡n transcription quality

#### MessageManager (message_manager.py)
- Quáº£n lÃ½ conversation history
- Multi-turn dialogue support
- Context preservation

#### FunctionRegistry (function_calling.py)
- Function calling cho OpenAI
- Mock data schema
- Function definitions

#### BatchProcessor (batch_processor.py)
- Batch processing nhiá»u requests
- Thread pool execution
- Timeout handling

#### WhisperModelCache (whisper_model_cache.py)
- Singleton cache cho Whisper models
- Preload models khi server start
- Thread-safe vá»›i locks
- Reuse models across requests (khÃ´ng cáº§n load láº¡i)
- Background preloading Ä‘á»ƒ tá»‘i Æ°u performance

## Cáº¥u hÃ¬nh (config.py)

### API Configuration
- `OPENAI_BASE_URL`: Base URL cho OpenAI API
- `OPENAI_API_KEY`: API key
- `OPENAI_MODEL_TRANSCRIPTION`: Model cho transcription (whisper-1)
- `OPENAI_MODEL_SUMMARY`: Model cho summarization (GPT-5-mini)

### File Configuration
- `UPLOAD_FOLDER`: ThÆ° má»¥c lÆ°u files
- `MAX_FILE_SIZE`: KÃ­ch thÆ°á»›c file tá»‘i Ä‘a (100MB)

### Text Chunking
- `MAX_CHARS_PER_CHUNK`: 2000 chars
- `CHUNK_OVERLAP`: 200 chars

### Language Support
- Há»— trá»£: vi, en, zh, ja, ko, fr, de, es, other
- Language mapping cho Whisper API

## Xá»­ lÃ½ lá»—i vÃ  Fallback

### Transcription Fallback Chain
1. Thá»­ OpenAI Whisper API
2. Náº¿u 404: Thá»­ alternative URL (/v1)
3. Náº¿u váº«n fail: Fallback local Whisper
4. Local Whisper: Load model vÃ  transcribe

### File Size Handling
1. File â‰¤ 25MB: Process trá»±c tiáº¿p
2. File > 25MB: Compress trÆ°á»›c
3. Náº¿u váº«n > 25MB: Split thÃ nh chunks
4. Process tá»«ng chunk vÃ  combine

### Error Handling
- Validation errors: 400 Bad Request
- Processing errors: 500 Internal Server Error
- Detailed error messages cho user
- Logging Ä‘áº§y Ä‘á»§ cho debugging

## Tá»‘i Æ°u hÃ³a

### Vietnamese Optimization
- Model: "medium" thay vÃ¬ "base"
- Post-processing Ä‘á»ƒ sá»­a lá»—i
- Better accuracy

### Performance
- **Model Caching**: Whisper models chá»‰ load 1 láº§n, reuse cho táº¥t cáº£ requests
- **Preloading**: Models Ä‘Æ°á»£c preload khi server start (background thread)
- **Fast Model Access**: Model load tá»« cache < 0.1s (thay vÃ¬ 5+ giÃ¢y)
- Chunking Ä‘á»ƒ xá»­ lÃ½ files lá»›n
- Batch processing support
- Efficient memory usage

### User Experience
- Progress bar (simulated)
- Clear error messages
- Validation feedback
- Download link cho audio file

## Dependencies

### Required
- Flask: Web framework
- openai: OpenAI SDK
- openai-whisper: Local Whisper transcription

### Optional
- FFmpeg: Cho compression vÃ  splitting (required cho files lá»›n)

## API Endpoints Summary

| Method | Endpoint | Description | Input | Output |
|--------|----------|-------------|-------|--------|
| GET | `/` | Home page | - | HTML |
| POST | `/process-audio` | Process audio | FormData | JSON |
| GET | `/check-ffmpeg` | Check FFmpeg | - | JSON |
| GET | `/uploads/<filename>` | Serve file | filename | File |

## Data Flow

```
User Input (Audio + Topic + Language)
    â†“
[Frontend Validation]
    â†“
POST /process-audio
    â†“
[Backend Validation]
    â†“
[Save Audio File] â†’ AudioService
    â†“
[Transcribe Audio] â†’ AIService
    â”œâ”€â†’ [API Transcription] (if available)
    â””â”€â†’ [Local Whisper] (fallback)
        â”œâ”€â†’ [Get Model from Cache] (WhisperModelCache)
        â”‚   â””â”€â†’ [Load Model] (if not cached, then cache it)
        â”œâ”€â†’ [Transcribe] (CPU-intensive)
        â””â”€â†’ [Post-process] (Vietnamese)
    â†“
[Transcript Text]
    â†“
[Summarize] â†’ AIService
    â”œâ”€â†’ [Single Chunk] (if short)
    â””â”€â†’ [Chunked] (if long)
        â”œâ”€â†’ [Split Text]
        â”œâ”€â†’ [Summarize Chunks]
        â””â”€â†’ [Combine Summaries]
    â†“
[Summary Text]
    â†“
[Return JSON Response]
    â†“
[Frontend Display]
```

## Logging vÃ  Debugging

App sá»­ dá»¥ng Python `logging` module vÃ  `print()` statements. CÃ¡c log points:
- **Initialization**: Server start, service initialization, model preloading
- **File Operations**: File save, file size, file path
- **Transcription**: 
  - API attempts vÃ  fallback
  - Model loading (from cache hoáº·c fresh load)
  - Estimated vÃ  actual processing time
  - Progress updates
- **Summarization**: Chunk splitting, API calls, completion time
- **Error Handling**: Detailed error messages vá»›i context

Log format: `[MODULE] Message` Ä‘á»ƒ dá»… theo dÃµi

## Performance Considerations

### Transcription
- Local Whisper: CPU-intensive, cÃ³ thá»ƒ cháº­m
- Model size: medium/large cháº­m hÆ¡n base
- File size: Files lá»›n cáº§n nhiá»u thá»i gian

### Summarization
- API calls: Network latency
- Chunked processing: Multiple API calls
- Token limits: Model context limits

### Memory
- Whisper models: ~1.5GB (medium)
- Large files: Memory usage khi processing
- Chunking: Giáº£m memory usage

## Troubleshooting

### App treo á»Ÿ 72%
- CÃ³ thá»ƒ Ä‘ang load Whisper model (láº§n Ä‘áº§u)
- Hoáº·c Ä‘ang transcribe (CPU-intensive)
- Check logs Ä‘á»ƒ xem Ä‘ang á»Ÿ bÆ°á»›c nÃ o

### FP16 Warning
- BÃ¬nh thÆ°á»ng khi cháº¡y Whisper trÃªn CPU
- Whisper tá»± Ä‘á»™ng dÃ¹ng FP32 thay vÃ¬ FP16

### Memory Issues
- Giáº£m model size (base thay vÃ¬ medium)
- Giáº£m file size trÆ°á»›c khi upload
- Close other applications

### Model Loading
- Models Ä‘Æ°á»£c preload khi server start (background thread)
- Láº§n Ä‘áº§u cÃ³ thá»ƒ máº¥t vÃ i giÃ¢y Ä‘á»ƒ download model
- CÃ¡c láº§n sau: instant tá»« cache (< 0.1s)
- Check logs Ä‘á»ƒ xem model loading status

### Server Configuration
- **Auto-reloader disabled**: Táº¯t Ä‘á»ƒ trÃ¡nh lá»—i socket khi Ä‘ang xá»­ lÃ½ transcription dÃ i
- **Threaded mode**: Cho phÃ©p xá»­ lÃ½ nhiá»u requests Ä‘á»“ng thá»i
- **Warning suppression**: Táº¯t cÃ¡c warnings khÃ´ng cáº§n thiáº¿t (FP16, etc.)
- **Graceful shutdown**: Xá»­ lÃ½ tÃ­n hiá»‡u shutdown Ä‘Ãºng cÃ¡ch

---

# HÆ°á»›ng dáº«n CÃ i Ä‘áº·t vÃ  Sá»­ dá»¥ng

## YÃªu cáº§u Há»‡ thá»‘ng

### Há»‡ Ä‘iá»u hÃ nh
- **Windows**: Windows 10/11 hoáº·c má»›i hÆ¡n
- **Linux**: Ubuntu 18.04+ hoáº·c cÃ¡c distro tÆ°Æ¡ng tá»±
- **macOS**: macOS 10.14+ hoáº·c má»›i hÆ¡n

### Pháº§n má»m cáº§n thiáº¿t

#### 1. Python
- **Version**: Python 3.8 hoáº·c má»›i hÆ¡n (khuyáº¿n nghá»‹ Python 3.10+)
- **CÃ¡ch kiá»ƒm tra**: Má»Ÿ terminal/cmd vÃ  cháº¡y `python --version`
- **CÃ¡ch cÃ i Ä‘áº·t**:
  - Windows: Download tá»« [python.org](https://www.python.org/downloads/)
  - Linux: `sudo apt-get install python3 python3-pip` (Ubuntu/Debian)
  - macOS: `brew install python3` hoáº·c download tá»« python.org

#### 2. FFmpeg (Báº¯t buá»™c)
FFmpeg cáº§n thiáº¿t cho Whisper Ä‘á»ƒ xá»­ lÃ½ audio files.

**Windows:**
1. Download tá»«: https://www.gyan.dev/ffmpeg/builds/ffmpeg-release-essentials.zip
2. Giáº£i nÃ©n vÃ o thÆ° má»¥c (vÃ­ dá»¥: `C:\ffmpeg`)
3. ThÃªm vÃ o PATH:
   - Nháº¥n `Win + X` â†’ chá»n "System"
   - Click "Advanced system settings"
   - Click "Environment Variables"
   - Trong "System variables", tÃ¬m "Path" â†’ click "Edit"
   - Click "New" â†’ thÃªm: `C:\ffmpeg\bin`
   - Click "OK" trÃªn táº¥t cáº£ cÃ¡c há»™p thoáº¡i
4. Khá»Ÿi Ä‘á»™ng láº¡i terminal/IDE
5. Kiá»ƒm tra: `ffmpeg -version`

**Linux (Ubuntu/Debian):**
```bash
sudo apt-get update
sudo apt-get install ffmpeg
```

**macOS:**
```bash
brew install ffmpeg
```

**Hoáº·c dÃ¹ng Chocolatey (Windows):**
```powershell
choco install ffmpeg
```

## CÃ i Ä‘áº·t Dependencies

### BÆ°á»›c 1: Clone hoáº·c táº£i project
```bash
cd C:\Users\PhamDucDuy        \Desktop\Python
```

### BÆ°á»›c 2: Táº¡o virtual environment (khuyáº¿n nghá»‹)
```bash
# Windows
python -m venv venv
venv\Scripts\activate

# Linux/macOS
python3 -m venv venv
source venv/bin/activate
```

### BÆ°á»›c 3: CÃ i Ä‘áº·t packages
```bash
pip install -r requirements.txt
```

**Dependencies sáº½ Ä‘Æ°á»£c cÃ i:**
- `flask>=2.0.0` - Web framework
- `openai>=1.0.0` - OpenAI SDK
- `openai-whisper>=20231117` - Local Whisper transcription

**LÆ°u Ã½:**
- Whisper sáº½ tá»± Ä‘á»™ng download models khi cáº§n (láº§n Ä‘áº§u sá»­ dá»¥ng)
- Model "medium" (~1.5GB) sáº½ Ä‘Æ°á»£c download cho tiáº¿ng Viá»‡t
- Model "base" (~150MB) sáº½ Ä‘Æ°á»£c download cho cÃ¡c ngÃ´n ngá»¯ khÃ¡c
- Models Ä‘Æ°á»£c lÆ°u trong cache cá»§a Whisper (thÆ°á»ng á»Ÿ `~/.cache/whisper/`)

## Cáº¥u hÃ¬nh

### Chá»‰nh sá»­a config.py (náº¿u cáº§n)

Má»Ÿ file `config.py` vÃ  kiá»ƒm tra cÃ¡c cáº¥u hÃ¬nh:

```python
# OpenAI API Configuration
OPENAI_BASE_URL = "https://aiportalapi.stu-platform.live/use"
OPENAI_API_KEY = "sk-6gH161QwRXLB0FmOCwxglA"
OPENAI_MODEL_TRANSCRIPTION = "whisper-1"
OPENAI_MODEL_SUMMARY = "GPT-5-mini"
```

**LÆ°u Ã½**: Náº¿u API khÃ´ng há»— trá»£ transcription, app sáº½ tá»± Ä‘á»™ng fallback sang local Whisper.

## Cháº¡y á»¨ng dá»¥ng

### BÆ°á»›c 1: Khá»Ÿi Ä‘á»™ng server
```bash
python app.py
```

Hoáº·c:
```bash
python -m flask run
```

### BÆ°á»›c 2: Má»Ÿ trÃ¬nh duyá»‡t
Truy cáº­p: `http://127.0.0.1:5000` hoáº·c `http://localhost:5000`

### BÆ°á»›c 3: Sá»­ dá»¥ng á»©ng dá»¥ng

1. **Nháº­p thÃ´ng tin:**
   - Meeting Topic: Nháº­p chá»§ Ä‘á» cuá»™c há»p (báº¯t buá»™c)
   - Conversation Language: Chá»n ngÃ´n ngá»¯ (báº¯t buá»™c)

2. **Upload audio:**
   - Click "ğŸ“ Or Upload Audio File" Ä‘á»ƒ chá»n file
   - Hoáº·c click "ğŸ¤ Start Recording" Ä‘á»ƒ ghi Ã¢m trá»±c tiáº¿p

3. **Xá»­ lÃ½:**
   - Click "ğŸ“¤ Process Audio File" (náº¿u upload file)
   - Hoáº·c click "â¹ï¸ Stop Recording" (náº¿u ghi Ã¢m)
   - Äá»£i quÃ¡ trÃ¬nh xá»­ lÃ½ hoÃ n táº¥t

4. **Xem káº¿t quáº£:**
   - Summary sáº½ hiá»ƒn thá»‹ sau khi xá»­ lÃ½ xong
   - CÃ³ thá»ƒ download audio file Ä‘Ã£ upload

## Láº§n Ä‘áº§u cháº¡y

Khi cháº¡y láº§n Ä‘áº§u, báº¡n sáº½ tháº¥y:

1. **Server khá»Ÿi Ä‘á»™ng:**
   ```
   [AISERVICE] Started preloading common Whisper models in background...
   [WHISPER CACHE] Preloading model 'base' in background...
   [WHISPER CACHE] Preloading model 'medium' in background...
   ```

2. **Models Ä‘Æ°á»£c download:**
   - Láº§n Ä‘áº§u: Models sáº½ Ä‘Æ°á»£c download (~1.5GB cho medium, ~150MB cho base)
   - CÃ³ thá»ƒ máº¥t vÃ i phÃºt tÃ¹y vÃ o tá»‘c Ä‘á»™ internet
   - Models Ä‘Æ°á»£c cache, khÃ´ng cáº§n download láº¡i

3. **Request Ä‘áº§u tiÃªn:**
   - Náº¿u model chÆ°a preload xong, sáº½ Ä‘á»£i model load
   - CÃ¡c request sau sáº½ nhanh hÆ¡n (model Ä‘Ã£ cÃ³ trong cache)

## Kiá»ƒm tra Logs

Khi cháº¡y app, logs sáº½ hiá»ƒn thá»‹ trong terminal:

```
2025-11-16 14:49:34 - __main__ - INFO - Initializing Flask application...
[AISERVICE] Started preloading common Whisper models in background...
[WHISPER CACHE] Preloading model 'base' in background...
[WHISPER CACHE] âœ“ Model 'base' loaded and cached in 2.30 seconds
```

**CÃ¡c log quan trá»ng:**
- `[AISERVICE]` - AI service operations
- `[WHISPER CACHE]` - Model loading vÃ  caching
- `[LOCAL WHISPER]` - Transcription process
- `[SUMMARIZATION]` - Summarization process
- `[AUDIO SERVICE]` - File operations

## Xá»­ lÃ½ Lá»—i ThÆ°á»ng gáº·p

### Lá»—i: "FFmpeg is not installed"
**Giáº£i phÃ¡p**: CÃ i Ä‘áº·t FFmpeg theo hÆ°á»›ng dáº«n á»Ÿ trÃªn vÃ  khá»Ÿi Ä‘á»™ng láº¡i terminal.

### Lá»—i: "ModuleNotFoundError: No module named 'whisper'"
**Giáº£i phÃ¡p**: 
```bash
pip install openai-whisper
```

### Lá»—i: "API endpoint not found (404)"
**Giáº£i phÃ¡p**: ÄÃ¢y lÃ  bÃ¬nh thÆ°á»ng. App sáº½ tá»± Ä‘á»™ng fallback sang local Whisper.

### App treo á»Ÿ 72%
**Giáº£i phÃ¡p**: 
- ÄÃ¢y khÃ´ng pháº£i lá»—i, app Ä‘ang transcribe audio (CPU-intensive)
- Vá»›i file 6MB, cÃ³ thá»ƒ máº¥t 8-10 phÃºt
- Check logs Ä‘á»ƒ xem progress: `[LOCAL WHISPER] Transcription started - processing audio...`
- UI progress bar lÃ  simulated, khÃ´ng pháº£n Ã¡nh thá»±c táº¿
- Äá»£i cho Ä‘áº¿n khi tháº¥y log: `[LOCAL WHISPER] âœ“ Transcription completed`

### Lá»—i: "OSError: [WinError 10038] An operation was attempted on something that is not a socket"
**Giáº£i phÃ¡p**: 
- ÄÃ£ Ä‘Æ°á»£c fix báº±ng cÃ¡ch táº¯t auto-reloader (`use_reloader=False`)
- Lá»—i nÃ y xáº£y ra khi Flask cá»‘ reload code trong khi Ä‘ang xá»­ lÃ½ request
- KhÃ´ng chá»‰nh sá»­a code trong khi Ä‘ang xá»­ lÃ½ transcription

### Memory Issues
**Giáº£i phÃ¡p**:
- ÄÃ³ng cÃ¡c á»©ng dá»¥ng khÃ¡c
- Giáº£m model size (sá»­a code Ä‘á»ƒ dÃ¹ng "base" thay vÃ¬ "medium")
- Giáº£m file size trÆ°á»›c khi upload

## Tá»‘i Æ°u Performance

### Cho tá»‘c Ä‘á»™ nhanh nháº¥t:
1. **Sá»­ dá»¥ng model "base"** thay vÃ¬ "medium" (sá»­a trong code)
2. **Giáº£m file size** trÆ°á»›c khi upload (< 5MB)
3. **Äáº£m báº£o FFmpeg Ä‘Ã£ cÃ i** Ä‘á»ƒ trÃ¡nh lá»—i
4. **Äá»ƒ models preload** khi server start (Ä‘Ã£ tá»± Ä‘á»™ng)

### Cho Ä‘á»™ chÃ­nh xÃ¡c cao nháº¥t (tiáº¿ng Viá»‡t):
1. **Giá»¯ model "medium"** (máº·c Ä‘á»‹nh cho tiáº¿ng Viá»‡t)
2. **File audio cháº¥t lÆ°á»£ng tá»‘t** (rÃµ rÃ ng, Ã­t noise)
3. **Chá»n Ä‘Ãºng ngÃ´n ngá»¯** trong form

## Cáº¥u trÃºc ThÆ° má»¥c sau khi cháº¡y

```
Python/
â”œâ”€â”€ uploads/                    # Files audio Ä‘Ã£ upload
â”‚   â””â”€â”€ recording_*.mp3
â”œâ”€â”€ __pycache__/               # Python cache files
â””â”€â”€ .cache/                    # Whisper model cache (tá»± Ä‘á»™ng táº¡o)
    â””â”€â”€ whisper/
        â”œâ”€â”€ base.pt            # Model base (~150MB)
        â””â”€â”€ medium.pt          # Model medium (~1.5GB)
```

## Há»— trá»£

Náº¿u gáº·p váº¥n Ä‘á»:
1. Check logs trong terminal
2. Kiá»ƒm tra FFmpeg Ä‘Ã£ cÃ i Ä‘Ãºng chÆ°a: `ffmpeg -version`
3. Kiá»ƒm tra Python version: `python --version`
4. Kiá»ƒm tra dependencies: `pip list`
5. Xem pháº§n Troubleshooting á»Ÿ trÃªn
